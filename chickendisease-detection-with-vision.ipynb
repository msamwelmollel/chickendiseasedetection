{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#from kaggle_datasets import KaggleDatasets\n#GCS_DS_PATH = KaggleDatasets().get_gcs_path()","metadata":{"execution":{"iopub.status.busy":"2023-04-20T13:50:07.241572Z","iopub.execute_input":"2023-04-20T13:50:07.242107Z","iopub.status.idle":"2023-04-20T13:50:07.262198Z","shell.execute_reply.started":"2023-04-20T13:50:07.242006Z","shell.execute_reply":"2023-04-20T13:50:07.261589Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"!pip install -U efficientnet\nimport efficientnet.keras as efn","metadata":{"execution":{"iopub.status.busy":"2023-04-20T13:50:07.263353Z","iopub.execute_input":"2023-04-20T13:50:07.263567Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Collecting efficientnet\n  Downloading efficientnet-1.1.1-py3-none-any.whl (18 kB)\nCollecting keras-applications<=1.0.8,>=1.0.7\n  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n     |████████████████████████████████| 50 kB 2.8 MB/s            \n\u001b[?25hRequirement already satisfied: scikit-image in /opt/conda/lib/python3.7/site-packages (from efficientnet) (0.18.3)\nRequirement already satisfied: numpy>=1.9.1 in /opt/conda/lib/python3.7/site-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (1.19.5)\nRequirement already satisfied: h5py in /opt/conda/lib/python3.7/site-packages (from keras-applications<=1.0.8,>=1.0.7->efficientnet) (3.1.0)\nRequirement already satisfied: scipy>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet) (1.7.2)\nRequirement already satisfied: networkx>=2.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet) (2.6.3)\nRequirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet) (8.2.0)\nRequirement already satisfied: PyWavelets>=1.1.1 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet) (1.2.0)\nRequirement already satisfied: imageio>=2.3.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet) (2.9.0)\nRequirement already satisfied: tifffile>=2019.7.26 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet) (2021.11.2)\nRequirement already satisfied: matplotlib!=3.0.0,>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-image->efficientnet) (3.5.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (1.3.2)\nRequirement already satisfied: fonttools>=4.22.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (4.28.2)\nRequirement already satisfied: setuptools-scm>=4 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (6.3.2)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (21.0)\nRequirement already satisfied: pyparsing>=2.2.1 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (3.0.6)\nRequirement already satisfied: cycler>=0.10 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (0.11.0)\nRequirement already satisfied: python-dateutil>=2.7 in /opt/conda/lib/python3.7/site-packages (from matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (2.8.0)\nRequirement already satisfied: cached-property in /opt/conda/lib/python3.7/site-packages (from h5py->keras-applications<=1.0.8,>=1.0.7->efficientnet) (1.5.2)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.7/site-packages (from python-dateutil>=2.7->matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (1.15.0)\nRequirement already satisfied: tomli>=1.0.0 in /opt/conda/lib/python3.7/site-packages (from setuptools-scm>=4->matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (1.2.2)\nRequirement already satisfied: setuptools in /opt/conda/lib/python3.7/site-packages (from setuptools-scm>=4->matplotlib!=3.0.0,>=2.0.0->scikit-image->efficientnet) (59.1.1)\nInstalling collected packages: keras-applications, efficientnet\nSuccessfully installed efficientnet-1.1.1 keras-applications-1.0.8\n\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\n","output_type":"stream"}]},{"cell_type":"code","source":"pip install matplotlib2tikz","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport datetime\nfrom itertools import permutations\nfrom tqdm import tqdm\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport re\nimport tensorflow as tf\nfrom sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\nfrom sklearn.metrics import classification_report\nfrom keras.callbacks import LearningRateScheduler, ModelCheckpoint\n\nfrom matplotlib import pyplot as plt\nprint(\"Tensorflow version \" + tf.__version__)\nAUTO = tf.data.experimental.AUTOTUNE\nfrom kaggle_datasets import KaggleDatasets\n\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Detect hardware, return appropriate distribution strategy\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection. No parameters necessary if TPU_NAME environment variable is set. On Kaggle this is always the case.\n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    strategy = tf.distribute.get_strategy() # default distribution strategy in Tensorflow. Works on CPU and single GPU.\n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)","metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!ls /kaggle/input/\n#!ls /kaggle/working/\n\n#!gsutil ls $GCS_PATH\nGCS_PATH = KaggleDatasets().get_gcs_path('hopenet')\n#print(GCS_PATH)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"models = []\nhistories = []\n\nEPOCHS = 50\nim = 512   # choose the image size 160, 224, 331, 512\nIMAGE_SIZE = [im, im]\nTARGET_SIZE = [im, im]\n\nFLOWERS_DATASETS = { # available image sizes\n    160: GCS_PATH + '/tfrecords-jpeg-160x160/train/*.tfrec',\n    224: GCS_PATH + '/tfrecords-jpeg-224x224/train/*.tfrec',\n    331: GCS_PATH + '/tfrecords-jpeg-331x331/train/*.tfrec',\n    512: GCS_PATH + '/*.tfrec',\n    #512: GCS_PATH + '/tfrecords-jpeg-512x512/train/*.tfrec',\n}\nCLASSES = ['cocci', 'healthy', 'salmo'] # do not change, maps to the labels in the data (folder names)\nassert IMAGE_SIZE[0] == IMAGE_SIZE[1], \"only square images are supported\"\nassert IMAGE_SIZE[0] in FLOWERS_DATASETS, \"this image size is not supported\"\n\nIMAGE_SIZE[0]\n\n\n\n# Learning rate schedule for TPU, GPU and CPU.\n# Using an LR ramp up because fine-tuning a pre-trained model.\n# Starting with a high LR would break the pre-trained weights.\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"BATCH_SIZE = 2 * strategy.num_replicas_in_sync # this is 8 on TPU v3-8, it is 1 on CPU and\nLR_START = 0.00001\nLR_MAX = 0.000012 * strategy.num_replicas_in_sync\nLR_MIN = 0.00001\nLR_RAMPUP_EPOCHS = 10\nLR_SUSTAIN_EPOCHS = 0\nLR_EXP_DECAY = .8\n\ndef lrfn(epoch):\n    if epoch < LR_RAMPUP_EPOCHS:\n        lr = (LR_MAX - LR_START) / LR_RAMPUP_EPOCHS * epoch + LR_START\n    elif epoch < LR_RAMPUP_EPOCHS + LR_SUSTAIN_EPOCHS:\n        lr = LR_MAX\n    else:\n        lr = (LR_MAX - LR_MIN) * LR_EXP_DECAY**(epoch - LR_RAMPUP_EPOCHS - LR_SUSTAIN_EPOCHS) + LR_MIN\n    return lr\n    \nlr_callback = tf.keras.callbacks.LearningRateScheduler(lrfn, verbose=True)\n\nrng = [i for i in range(EPOCHS)]\ny = [lrfn(x) for x in rng]\nplt.plot(rng, y)\nprint(\"Learning rate schedule: {:.3g} to {:.3g} to {:.3g}\".format(y[0], max(y), y[-1]))\nBATCH_SIZE","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def dataset_to_numpy_util(dataset, N):\n    dataset = dataset.unbatch().batch(N)\n    for images, labels in dataset:\n        numpy_images = images.numpy()\n        numpy_labels = labels.numpy()\n        break;  \n    return numpy_images, numpy_labels\n\ndef title_from_label_and_target(label, correct_label):\n    label = np.argmax(label, axis=-1)  # one-hot to class number\n    correct_label = np.argmax(correct_label, axis=-1) # one-hot to class number\n    correct = (label == correct_label)\n    return \"{} [{}{}{}]\".format(CLASSES[label], str(correct), ', shoud be ' if not correct else '',\n                                CLASSES[correct_label] if not correct else ''), correct\n\ndef display_one_flower(image, title, subplot, red=False):\n    plt.subplot(subplot)\n    plt.axis('off')\n    plt.imshow(image)\n    plt.title(title, fontsize=16, color='red' if red else 'black')\n    return subplot+1\n\n\ndef display_9_images_from_dataset(dataset):\n    subplot=331\n    plt.figure(figsize=(13,13))\n    images, labels = dataset_to_numpy_util(dataset, 9)\n    for i, image in enumerate(images):\n        title = CLASSES[np.argmax(labels[i], axis=-1)]\n        subplot = display_one_flower(image, title, subplot)\n        if i >= 8:\n            break;\n              \n    plt.tight_layout()\n    plt.subplots_adjust(wspace=0.1, hspace=0.1)\n    plt.show()  \n\n    \ndef display_9_images_with_predictions(images, predictions, labels):\n    subplot=331\n    plt.figure(figsize=(13,13))\n    for i, image in enumerate(images):\n        title, correct = title_from_label_and_target(predictions[i], labels[i])\n        subplot = display_one_flower(image, title, subplot, not correct)\n        if i >= 8:\n            break;\n              \n    plt.tight_layout()\n    plt.subplots_adjust(wspace=0.1, hspace=0.1)\n    plt.show()\n    \ndef display_confusion_matrix(cmat, score, precision, recall):\n    plt.figure(figsize=(15,15))\n    ax = plt.gca()\n    ax.matshow(cmat, cmap='Reds')\n    ax.set_xticks(range(len(CLASSES)))\n    ax.set_xticklabels(CLASSES, fontdict={'fontsize': 7})\n    plt.setp(ax.get_xticklabels(), rotation=45, ha=\"left\", rotation_mode=\"anchor\")\n    ax.set_yticks(range(len(CLASSES)))\n    ax.set_yticklabels(CLASSES, fontdict={'fontsize': 7})\n    plt.setp(ax.get_yticklabels(), rotation=45, ha=\"right\", rotation_mode=\"anchor\")\n    titlestring = \"\"\n    if score is not None:\n        titlestring += 'f1 = {:.3f} '.format(score)\n    if precision is not None:\n        titlestring += '\\nprecision = {:.3f} '.format(precision)\n    if recall is not None:\n        titlestring += '\\nrecall = {:.3f} '.format(recall)\n    if len(titlestring) > 0:\n        ax.text(101, 1, titlestring, fontdict={'fontsize': 18, 'horizontalalignment':'right', 'verticalalignment':'top', 'color':'#804040'})\n    plt.show()\n    \n\ndef display_training_curves(training, validation, title, subplot):\n    if subplot%10==1: # set up the subplots on the first call\n        plt.subplots(figsize=(10,10), facecolor='#F0F0F0')\n        plt.tight_layout()\n    ax = plt.subplot(subplot)\n    ax.set_facecolor('#F8F8F8')\n    ax.plot(training)\n    ax.plot(validation)\n    ax.set_title('model '+ title)\n    ax.set_ylabel(title)\n    #ax.set_ylim(0.28,1.05)\n    ax.set_xlabel('epoch')\n    ax.legend(['train', 'valid.'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def count_data_items(filenames):\n    # the number of data items is written in the name of the .tfrec files, i.e. flowers00-230.tfrec = 230 data items\n    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n    return np.sum(n)\n\n\n\ngcs_pattern = FLOWERS_DATASETS[IMAGE_SIZE[0]]\n#validation_split = 0.15\nvalid_split = 0.2\ntest_split = 0.2\nvalidation_split = valid_split + test_split\nfilenames = tf.io.gfile.glob(gcs_pattern)\nsplit = len(filenames) - int(len(filenames) * validation_split)\nTRAINING_FILENAMES = filenames[:split]\n\nsplit = len(filenames) - int(len(filenames) * validation_split)\nsplit1 = len(filenames) - int(len(filenames) * test_split)\n\nVALIDATION_FILENAMES = filenames[split:split1]\nTEST_FILENAMES = filenames[split1:]\n\n\n\nTRAIN_STEPS = count_data_items(TRAINING_FILENAMES) // BATCH_SIZE\nprint(\"TRAINING IMAGES: \", count_data_items(TRAINING_FILENAMES), \", STEPS PER EPOCH: \", TRAIN_STEPS)\nprint(\"VALIDATION IMAGES: \", count_data_items(VALIDATION_FILENAMES))\nprint(\"TEST IMAGES: \", count_data_items(TEST_FILENAMES))\n\n#NUM_TRAINING_IMAGES = count_data_items(TRAINING_FILENAMES)\nNUM_VALIDATION_IMAGES = count_data_items(VALIDATION_FILENAMES)\n\ndef read_tfrecord(example):\n    features = {\n        \"image\": tf.io.FixedLenFeature([], tf.string),  # tf.string = bytestring (not text string)\n        \"class\": tf.io.FixedLenFeature([], tf.int64),   # shape [] means scalar\n        \n        # additional (not very useful) fields to demonstrate TFRecord writing/reading of different types of data\n        \"label\":         tf.io.FixedLenFeature([], tf.string),  # one bytestring\n        \"size\":          tf.io.FixedLenFeature([2], tf.int64),  # two integers\n        \"one_hot_class\": tf.io.VarLenFeature(tf.float32)        # a certain number of floats\n    }\n    # decode the TFRecord\n    example = tf.io.parse_single_example(example, features)\n    \n    # FixedLenFeature fields are now ready to use: exmple['size']\n    # VarLenFeature fields require additional sparse_to_dense decoding\n    \n    image = tf.image.decode_jpeg(example['image'], channels=3)\n    image = tf.cast(image, tf.float32) / 255.0  # convert image to floats in [0, 1] range\n    \n    #image = tf.reshape(image, [*TARGET_SIZE, 3])\n    \n    #class_num = example['class']\n    class_num = tf.cast(example['class'], tf.int32)\n\n    \n    label  = example['label']\n    \n    height = example['size'][0]\n    width  = example['size'][1]\n    one_hot_class = tf.sparse.to_dense(example['one_hot_class'])\n    one_hot_class = tf.reshape(one_hot_class, [3])   # change whenever you changed the classes\n    return image, one_hot_class\n\n\n\n    #image = tf.cast(image, tf.float32) / 255.0  # convert image to floats in [0, 1] range\n    #class_label = tf.cast(example['class'], tf.int32)\n    #one_hot_class = tf.sparse.to_dense(example['one_hot_class'])\n    #one_hot_class = tf.reshape(one_hot_class, [5])\n    #return image, one_hot_class\n    \n\ndef force_image_sizes(dataset, image_size):\n    # explicit size needed for TPU\n    reshape_images = lambda image, label: (tf.reshape(image, [*image_size, 3]), label)\n    dataset = dataset.map(reshape_images, num_parallel_calls=AUTO)\n    return dataset\n\ndef load_dataset(filenames):\n    # Read from TFRecords. For optimal performance, reading from multiple files at once and\n    # disregarding data order. Order does not matter since we will be shuffling the data anyway.\n\n    ignore_order = tf.data.Options()\n    ignore_order.experimental_deterministic = False\n\n    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTO) # automatically interleaves reads from multiple files\n    dataset = dataset.with_options(ignore_order) # uses data as soon as it streams in, rather than in its original order\n    dataset = dataset.map(read_tfrecord, num_parallel_calls=AUTO)\n    dataset = force_image_sizes(dataset, IMAGE_SIZE)\n    return dataset\n\ndef data_augment(image, one_hot_class):\n    # data augmentation. Thanks to the dataset.prefetch(AUTO) statement in the next function (below),\n    # this happens essentially for free on TPU. Data pipeline code is executed on the \"CPU\" part\n    # of the TPU while the TPU itself is computing gradients.\n    #tf.image.resize_with_pad(image, target_height=IMAGE_SIZE[1], target_width=IMAGE_SIZE[1], method=tf.image.ResizeMethod.BILINEAR,antialias=False)\n    image = tf.image.random_flip_up_down(image)\n    image = tf.image.resize_with_crop_or_pad(image, IMAGE_SIZE[1]+10, IMAGE_SIZE[1]+10) # Add 6 pixels of padding\n    image = tf.image.random_crop(image, size=[IMAGE_SIZE[1], IMAGE_SIZE[1], 3]) # Random crop back to 28x28\n    #%%%\n    #image = tf.image.rotate(image,0.785)\n    #image = tf.image.random_brightness(image, max_delta=0.5)\n    #%%%\n    image = tf.image.random_flip_left_right(image)\n    image = tf.image.random_saturation(image, 0, 2)\n    \n    return image, one_hot_class  \n\ndef get_training_dataset():\n    dataset = load_dataset(TRAINING_FILENAMES)\n    dataset = dataset.map(data_augment, num_parallel_calls=AUTO)\n    dataset = dataset.repeat()\n    dataset = dataset.shuffle(2048)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.prefetch(AUTO) # prefetch next batch while training (autotune prefetch buffer size)\n    return dataset\n\ndef get_validation_dataset(ordered=False):\n    dataset = load_dataset(VALIDATION_FILENAMES)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.prefetch(AUTO) # prefetch next batch while training (autotune prefetch buffer size)\n    return dataset\n\n    #dataset = load_dataset(VALIDATION_FILENAMES, labeled=True, ordered=ordered)\n    #dataset = dataset.batch(BATCH_SIZE)\n    #dataset = dataset.cache()\n    #dataset = dataset.prefetch(AUTO) # prefetch next batch while training (autotune prefetch buffer size)\n    #return dataset\n    \ndef get_test_dataset(ordered=False):\n    dataset = load_dataset(TEST_FILENAMES)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.prefetch(AUTO) # prefetch next batch while training (autotune prefetch buffer size)\n    return dataset\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"training_dataset = get_training_dataset()\nvalidation_dataset = get_validation_dataset()\ntest_dataset = get_test_dataset()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras import metrics\ndef create_model(num):\n    if num == 1:\n        #pretrained_model = tf.keras.applications.MobileNetV2(input_shape=[*IMAGE_SIZE, 3], include_top=False)\n        #pretrained_model = tf.keras.applications.Xception(input_shape=[*IMAGE_SIZE, 3], include_top=False)\n        pretrained_model = tf.keras.applications.VGG16(weights='imagenet', include_top=False ,input_shape=[*IMAGE_SIZE, 3])\n        \n        #pretrained_model = tf.keras.applications.NASNetMobile(input_shape=[*IMAGE_SIZE, 3], include_top=True)\n        #pretrained_model = tf.keras.applications.InceptionResNetV2(input_shape=[*IMAGE_SIZE, 3], include_top=False, weights=\"imagenet\")\n    elif num==2:\n        #pretrained_model = tf.keras.applications.ResNet50(weights='imagenet', include_top=False, input_shape=[*IMAGE_SIZE, 3])\n        pretrained_model = efn.EfficientNetB0(input_shape = (512, 512, 3), include_top = False, weights = 'imagenet')\n    else:\n        #pretrained_model = tf.keras.applications.VGG16(weights='imagenet', include_top=False ,input_shape=[*IMAGE_SIZE, 3])\n        pretrained_model = tf.keras.applications.Xception(input_shape=[*IMAGE_SIZE, 3], include_top=False)\n        #pretrained_model = tf.keras.applications.InceptionResNetV2(input_shape=[*IMAGE_SIZE, 3], include_top=False, weights=\"imagenet\")\n            \n    #pretrained_model = tf.keras.applications.Xception(input_shape=[*IMAGE_SIZE, 3], include_top=False)\n    #pretrained_model = tf.keras.applications.VGG16(weights='imagenet', include_top=False ,input_shape=[*IMAGE_SIZE, 3])\n    #pretrained_model = tf.keras.applications.ResNet50(weights='imagenet', include_top=False, input_shape=[*IMAGE_SIZE, 3])\n    #pretrained_model = tf.keras.applications.MobileNet(weights='imagenet', include_top=False, input_shape=[*IMAGE_SIZE, 3])\n    # EfficientNet can be loaded through efficientnet.tfkeras library (https://github.com/qubvel/efficientnet)\n    #pretrained_model = efficientnet.tfkeras.EfficientNetB0(weights='imagenet', include_top=False)\n    \n    pretrained_model.trainable = True\n\n    model = tf.keras.Sequential([\n        pretrained_model,\n        tf.keras.layers.GlobalAveragePooling2D(),\n        #tf.keras.layers.Flatten(),\n        #sigmoid\n        #tf.keras.layers.Dense(1, activation='sigmoid')\n        tf.keras.layers.Dense(3, activation='softmax')\n        \n        #tf.keras.layers.Dense(1)\n    ])\n    \n\n   \n    model.compile(\n        optimizer='adam',\n        #loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n        loss = 'categorical_crossentropy',\n        #loss = tf.keras.losses.BinaryCrossentropy(from_logits=True),\n        #metrics=[tf.keras.metrics.BinaryAccuracy()]\n        #metrics = ['sparse_categorical_accuracy']\n        metrics = ['accuracy']\n    )\n\n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from keras.utils import to_categorical\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D\nfrom keras.layers import MaxPooling2D\nfrom keras.layers import Dense\nfrom keras.layers import Flatten\nfrom keras.layers import Dropout\nfrom keras.optimizers import SGD\nfrom keras.optimizers import Adam \ndef define_model2():\n    model = Sequential()\n    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same', input_shape=(512, 512, 3)))\n    model.add(MaxPooling2D((2, 2)))\n    # futa\n    model.add(Conv2D(32, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n    model.add(MaxPooling2D((2, 2)))\n    #futa\n    model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n    model.add(MaxPooling2D((2, 2)))\n    model.add(Conv2D(64, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n    model.add(MaxPooling2D((2, 2)))\n    model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n    model.add(MaxPooling2D((2, 2)))\n    model.add(Conv2D(128, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n    model.add(MaxPooling2D((2, 2)))\n    model.add(Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n    model.add(MaxPooling2D((2, 2)))\n    #model.add(Conv2D(256, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n    #model.add(MaxPooling2D((2, 2)))\n    model.add(Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n    model.add(MaxPooling2D((2, 2)))\n    #model.add(Conv2D(512, (3, 3), activation='relu', kernel_initializer='he_uniform', padding='same'))\n    #model.add(MaxPooling2D((2, 2)))\n    model.add(Flatten())\n    #model.add(Dense(256, activation='relu', kernel_initializer='he_uniform'))\n    #model.add(Dense(2048, activation='relu', kernel_initializer='he_uniform'))\n    model.add(Dense(1024, activation='relu', kernel_initializer='he_uniform'))\n    #model.add(Dense(128, activation='relu', kernel_initializer='he_uniform'))\n    model.add(Dense(3, activation='softmax'))\n    # compile model\n    #opt = SGD(lr=0.0001, momentum=0.9)\n    opt = Adam()\n    model.compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n    return model","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with strategy.scope():\n    #model = create_model(0)\n    #model_1 = create_model(1)\n    model_2 = create_model(2)\n    #model_3 = define_model2()\n    \n#model.summary()\n#model_1.summary()\n\n#models.append(model)\n#models.append(model_1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#output_dir = '/temp'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#callbacks = [lr_callback, ModelCheckpoint(str(output_dir) + \"/weights0.{epoch:03d}-{val_loss:.3f}-{val_accuracy:.3f}.hdf5\",\n#                             monitor=\"val_loss\",\n#                             verbose=1,\n#                             save_best_only=True,\n#                             mode=\"min\")]\n\n#date_1  = datetime.datetime.today()\n#history = model.fit(training_dataset, validation_data=validation_dataset,\n#                    steps_per_epoch=TRAIN_STEPS, epochs=EPOCHS, callbacks=callbacks)\n#date_2 =  datetime.datetime.today()\n#histories.append(history)\n\n#final_accuracy = history.history[\"val_accuracy\"][-5:]\n#print(\"FINAL ACCURACY MEAN-5: \", np.mean(final_accuracy))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#date_1  = datetime.datetime.today()\n#history = model_1.fit(training_dataset, validation_data=validation_dataset,\n#                    steps_per_epoch=TRAIN_STEPS, epochs=EPOCHS, callbacks=[lr_callback])\n#date_2 =  datetime.datetime.today()\n#histories.append(history)\n\n#final_accuracy = history.history[\"val_accuracy\"][-5:]\n#print(\"FINAL ACCURACY MEAN-5: \", np.mean(final_accuracy))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"date_1  = datetime.datetime.today()\nhistory = model_2.fit(training_dataset, validation_data=validation_dataset,\n                    steps_per_epoch=TRAIN_STEPS, epochs= 15, callbacks=[lr_callback])\ndate_2 =  datetime.datetime.today()\nhistories.append(history)\n\nfinal_accuracy = history.history[\"val_accuracy\"][-5:]\nprint(\"FINAL ACCURACY MEAN-5: \", np.mean(final_accuracy))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#from sklearn.externals import joblib\n#import joblib\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#joblib_file = \"efficient_net.pkl\"   \n#joblib.dump(model_2, joblib_file)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#model_2.save(\"efficient_net.h5\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model_2.save(\"efficient_net_withouth5\")","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import shutil\nshutil.make_archive('OUTPUT_NAME', 'zip', 'efficient_net_withouth5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\ncallbacks = [lr_callback,\n             ModelCheckpoint(str(output_dir) + \"/weights.{epoch:03d}-{val_loss:.3f}-{val_accuracy:.3f}.hdf5\",\n                             monitor=\"val_loss\",\n                             verbose=1,\n                             save_best_only=True,\n                             mode=\"min\")]\nhistory = model_3.fit(training_dataset, validation_data=validation_dataset,\n                    steps_per_epoch=TRAIN_STEPS, epochs= 100, callbacks=callbacks)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"time_delta = (date_2 - date_1)\ntotal_seconds = time_delta.total_seconds()\nminutes = total_seconds/60\n\nprint(minutes)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.DataFrame(list(zip(history.history['accuracy'], history.history['val_accuracy'], history.history['loss'], history.history['val_loss'])), \n               columns =['Accuracy', 'val_accuracy', 'loss', 'val_loss']) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.to_csv ('metricxnet224.csv', index = False, header=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#history.history['accuracy']","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display_training_curves(history.history['accuracy'][1:], history.history['val_accuracy'][1:], 'accuracy', 211)\ndisplay_training_curves(history.history['loss'][1:], history.history['val_loss'][1:], 'loss', 212)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"display_training_curves(history.history['accuracy'][40:], history.history['val_accuracy'][40:], 'accuracy', 211)\ndisplay_training_curves(history.history['loss'][40:], history.history['val_loss'][40:], 'loss', 212)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# a couple of images to test predictions too\nsome_flowers, some_labels = dataset_to_numpy_util(validation_dataset, count_data_items(VALIDATION_FILENAMES))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# randomize the input so that you can execute multiple times to change results\npermutation = np.random.permutation(NUM_VALIDATION_IMAGES)\nsome_flowers, some_labels = (some_flowers[permutation], some_labels[permutation])\ndate_1  = datetime.datetime.today()\npredictions = model.predict(some_flowers, batch_size=16)\n\ndate_2  = datetime.datetime.today()\nevaluations = model.evaluate(some_flowers, some_labels, batch_size=16)\n  \nprint(np.array(CLASSES)[np.argmax(predictions, axis=-1)].tolist())\nprint('[val_loss, val_acc]', evaluations)\n\ndisplay_9_images_with_predictions(some_flowers, predictions, some_labels)\n\n\nfrom sklearn.metrics import log_loss\nsome_flowers, some_labels = dataset_to_numpy_util(validation_dataset, NUM_VALIDATION_IMAGES)\npredictions = model.predict(some_flowers, batch_size=16)\n#evaluations = model.evaluate(some_flowers, some_labels, batch_size=16)\n#clf_probs = clf.predict_proba(X_test)\nscore = log_loss(some_labels, predictions)\nprint(score)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"time_delta = (date_2 - date_1)\ntotal_seconds = time_delta.total_seconds()\nminutes = total_seconds/(60*NUM_VALIDATION_IMAGES)\n\nprint(minutes)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"minutes*60","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"some_flowers, some_labels = dataset_to_numpy_util(test_dataset, count_data_items(TEST_FILENAMES)) ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# randomize the input so that you can execute multiple times to change results\npermutation = np.random.permutation(count_data_items(TEST_FILENAMES))\nsome_flowers, some_labels = (some_flowers[permutation], some_labels[permutation])\n#print(type([np.argmax(some_labels, axis=-1)]))\n\npredictions = model.predict(some_flowers, batch_size=16)\nevaluations = model.evaluate(some_flowers, some_labels, batch_size=16)\n  \nprint(np.array(CLASSES)[np.argmax(predictions, axis=-1)].tolist())\nprint('[val_loss, val_acc]', evaluations)\n\ndisplay_9_images_with_predictions(some_flowers, predictions, some_labels)\n\n\nfrom sklearn.metrics import log_loss\nsome_flowers, some_labels = dataset_to_numpy_util(test_dataset, count_data_items(TEST_FILENAMES))\npredictions = model.predict(some_flowers, batch_size=16)\n#evaluations = model.evaluate(some_flowers, some_labels, batch_size=16)\n#clf_probs = clf.predict_proba(X_test)\nscore = log_loss(some_labels, predictions)\nresults = np.array(CLASSES)[np.argmax(predictions, axis=-1)].tolist()\nresultscon = np.argmax(predictions, axis=-1)\n#print(classification_report(some_labels, predictions))\n#print(score)\nresults1 = np.array(CLASSES)[np.argmax(some_labels, axis=-1)].tolist()\nresults1con = np.argmax(some_labels, axis=-1)\n\nprint(classification_report(results1, results, labels=['cocci', 'healthy', 'salmo']))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from itertools import permutations\nfrom tqdm import tqdm\nfrom sklearn.metrics import accuracy_score\ndef generate_dim_ratios(n):\n    switcher = {\n        1: 1e-01,\n        2: 1e-02,\n        3: (1e-02)/2,\n        4: (1e-02)/4,\n        5: (1e-02)/8,\n        6: (1e-02)/16,\n        7: (1e-02)/32,\n        8: (1e-02)/64,\n        9: (1e-02)/128,\n        10: (1e-02)/256,\n        11: (1e-02)/512,\n        12: (1e-02)/1024,\n        }\n    return switcher.get(n,\"Invalid space\")\n#SUBMOD05:---------------------------------------------------------------------\ndef generate_weights_vector(ranks_prec_degree):\n    #Generating initial weights distributions\n    default_ratio = generate_dim_ratios(ranks_prec_degree)\n    weights_vector = []\n    weights_vector.append(0.0)\n    for i in range (0,int(1/default_ratio) ):\n        rational_wts = default_ratio + (default_ratio * i)\n        weights_vector.append(round(rational_wts,12))    \n    return default_ratio, weights_vector\n#SUBMOD06:---------------------------------------------------------------------\n\n\n#SUBMOD09:---------------------------------------------------------------------\ndef create_MatrixA_clrsweigths(weights_vector,ci):\n    'maxrnk1_Perm_CLRSWGHTS_mxn'\n    clrs_weights_matrix = []\n    base_weight_vector = permutations(weights_vector,len(ci))#Permute clrswts\n    for i in list (base_weight_vector):\n        clrs_weights_matrix.append(i)\n    clrs_weights_matrix =\\\n        pd.DataFrame(clrs_weights_matrix, columns=['dt','rf','nn','gb'])\n    # Taking only the rows whose ranking totals to 1 \n    MAT_A_CLRSWGHTS_mxn = clrs_weights_matrix\\\n        [(clrs_weights_matrix['dt'] + clrs_weights_matrix['rf'] + \\\n        clrs_weights_matrix['nn'] + clrs_weights_matrix['gb']) == 1] \n    return MAT_A_CLRSWGHTS_mxn # returns DataFrame\n#SUBMOD10:---------------------------------------------------------------------\ndef gen_classifiers_initials(names):\n    ci = []\n    for c_i in range(0,len(names)):\n        namep1,namep2 = names[c_i].split(' ',1)\n        clrs_nmi = namep1[0]+namep2[0]\n        ci.append(clrs_nmi.strip())\n    return ci\n#SUBMOD13:---------------------------------------------------------------------\n    ","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# randomize the input so that you can execute multiple times to change results\npermutation = np.random.permutation(count_data_items(TEST_FILENAMES))\nsome_flowers, some_labels = (some_flowers[permutation], some_labels[permutation])\n\npredictions = model.predict(some_flowers, batch_size=16)\nnp.savetxt(\"predictions.csv\", predictions, delimiter=\",\")\npredictions1 = model_1.predict(some_flowers, batch_size=16)\nnp.savetxt(\"predictions1.csv\", predictions1, delimiter=\",\")\npredictions2 = model_2.predict(some_flowers, batch_size=16)\nnp.savetxt(\"predictions2.csv\", predictions2, delimiter=\",\")\npredictions3 = model_3.predict(some_flowers, batch_size=16)\nnp.savetxt(\"predictions3.csv\", predictions3, delimiter=\",\")\nnp.savetxt(\"some_labels.csv\", some_labels, delimiter=\",\")\n\n\n\nclrs_names = [\"Decision Tree\", \"Random Forest\", \"Neural Net\", \"Gradient Boost\"]\ndefault_ratio, weights_vector = generate_weights_vector(1)\nci = gen_classifiers_initials(clrs_names)\n# # #Matrix A --  permuted weights for available classifiers\nMAT_A_CLRSWGHTS_mxn = create_MatrixA_clrsweigths(weights_vector,ci)\n# print(MAT_A_CLRSWGHTS_mxn)\ndt = predictions\nrf = predictions1\nnn = predictions2\ngb = predictions3\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"linker_dict = {'dt':dt,'rf':rf,'nn':nn,'gb':gb}\nci_of_probpred = ['dt','rf','nn','gb']\nci_of_probpred_perm = permutations(ci_of_probpred)\nci_of_probpred_perm_list = list(ci_of_probpred_perm)\nk = list(permutations(ci_of_probpred))\nfor i in tqdm(range(len(ci_of_probpred_perm_list)), desc = \"Creating grid search space\"):\n    ci_of_probpred_perm_list[i] = list(ci_of_probpred_perm_list[i])\n    for j in range(len(ci_of_probpred_perm_list[i])):\n       ci_of_probpred_perm_list[i][j] = linker_dict[ci_of_probpred_perm_list[i][j]]\nMAT_B_CLRSPROBAPRED_nxm = ci_of_probpred_perm_list","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"MAT_A_CLRSWGHTS_mxn = np.asarray(MAT_A_CLRSWGHTS_mxn)\nMAT_A_1stexp = np.expand_dims(MAT_A_CLRSWGHTS_mxn,axis = 0)\nMAT_A_2ndexp = np.expand_dims(MAT_A_1stexp,axis = 0)\n\nMAT_A_2ndexp_rs = np.reshape(MAT_A_2ndexp,(MAT_A_CLRSWGHTS_mxn.shape[0],MAT_A_CLRSWGHTS_mxn.shape[1],1,1))\n\nmax_score, i_val, j_val = 0,0,0\nfor i in tqdm(range(MAT_A_2ndexp_rs.shape[0]), desc = \"Optimizing Ensemble\"):\n    out1 = MAT_A_2ndexp_rs[i] * MAT_B_CLRSPROBAPRED_nxm \n    out2 = out1.sum(axis = 1)\n    for j in range(out2.shape[0]):\n        p = np.argmax(out2[j],axis = 1)\n        # print(out2[j].shape)\n        # if maximum < np.sum(out2[j])\n        multi_en_probpred = p\n\n        _DATA= [np.argmax(some_labels, axis=-1)]\n\n        score = accuracy_score(multi_en_probpred,_DATA[0])        \n        if score > max_score:\n            print(score)\n            max_score = score\n            i_val = i\n            j_val = j\n            \n            clrs_comb = list(k[j_val])\n            print(clrs_comb)\n            wts_comb = MAT_A_CLRSWGHTS_mxn[i_val]\n            print(wts_comb)\n\n#print(clrs_comb)\nensemb = \"\"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.DataFrame(list(zip(results1, results)), columns =['YTest', 'YPredict']) \ndf.to_csv ('con'+str(im)+'.csv', index = False, header=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = pd.DataFrame(list(zip(results1con, resultscon)), columns =['YTest', 'YPredict']) \ndf.to_csv ('con'+str(im)+'label.csv', index = False, header=True)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cmat = confusion_matrix(results1, results, labels=['cocci', 'healthy', 'salmo'])\nscore = f1_score(results1, results, labels=['cocci', 'healthy', 'salmo'], average='macro')\nprecision = precision_score(results1, results, labels=['cocci', 'healthy', 'salmo'], average='macro')\nrecall = recall_score(results1, results, labels=['cocci', 'healthy', 'salmo'], average='macro')\ncmat = (cmat.T / cmat.sum(axis=1)).T # normalized\ndisplay_confusion_matrix(cmat, score, precision, recall)\nprint('f1 score: {:.3f}, precision: {:.3f}, recall: {:.3f}'.format(score, precision, recall))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(classification_report(results1, results, labels=['cocci', 'healthy', 'salmo']))","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save('hopenet.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model.save_weights('hopenet1.h5')","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#cmdataset = get_validation_dataset(ordered=True) # since we are splitting the dataset and iterating separately on images and labels, order matters.\n#images_ds = cmdataset.map(lambda image, label: image)\n#labels_ds = cmdataset.map(lambda image, label: label).unbatch()\n#cm_correct_labels = next(iter(labels_ds.batch(NUM_VALIDATION_IMAGES))).numpy() # get everything as one batch\n#cm_probabilities = model.predict(images_ds)\n#cm_predictions = np.argmax(cm_probabilities, axis=-1)\n#print(\"Correct   labels: \", cm_correct_labels.shape, cm_correct_labels)\n#print(\"Predicted labels: \", cm_predictions.shape, cm_predictions)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#cmat = confusion_matrix(cm_correct_labels, cm_predictions, labels=range(len(CLASSES)))\n#score = f1_score(cm_correct_labels, cm_predictions, labels=range(len(CLASSES)), average='macro')\n#precision = precision_score(cm_correct_labels, cm_predictions, labels=range(len(CLASSES)), average='macro')\n#recall = recall_score(cm_correct_labels, cm_predictions, labels=range(len(CLASSES)), average='macro')\n#cmat = (cmat.T / cmat.sum(axis=1)).T # normalized\n#display_confusion_matrix(cmat, score, precision, recall)\n#print('f1 score: {:.3f}, precision: {:.3f}, recall: {:.3f}'.format(score, precision, recall))\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}